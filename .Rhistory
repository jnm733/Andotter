tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", tweet)
# Then remove all "#Hashtag"
tweet = gsub("#\\w+", " ", tweet)
# Then remove all "@people"
tweet = gsub("@\\w+", " ", tweet)
# Then remove all the punctuation
#tweet = gsub("[[:punct:]]", " ", tweet)
# Then remove numbers, we need only text for analytics
tweet = gsub("[[:digit:]]", " ", tweet)
# finally, we remove unnecessary spaces (white spaces, tabs etc)
tweet = gsub("[ \t]{2,}", " ", tweet)
tweet = gsub("^\\s+|\\s+$", "", tweet)
tweet = chartr('áéíóú','aeiou', tweet)
# if anything else, you feel, should be removed, you can. For example "slang words" etc using the above function and methods.
# Next we'll convert all the word in lower case. This makes uniform pattern.
tweet = catch.error(tweet)
tweet
}
cleanTweetsAndRemoveNAs = function(Tweets) {
TweetsCleaned = sapply(Tweets, cleanTweets)
# Remove the "NA" tweets from this tweet list
TweetsCleaned = TweetsCleaned[!is.na(TweetsCleaned)]
names(TweetsCleaned) = NULL
# Remove the repetitive tweets from this tweet list
TweetsCleaned = unique(TweetsCleaned)
TweetsCleaned
}
TextTweetsSpanish <- sapply(AnalisisTweetsSpanish, function(x) x$getText())
TextTweetsSpanish
TextTweetsSpanish = iconv(TextTweetsSpanish, "latin1", "UTF-8", sub="")
AnalisisTweetsLimpioSpanish = cleanTweetsAndRemoveNAs(TextTweetsSpanish)
AnalisisTweetsLimpioSpanish
library(stringr)
#Función para convertir en minuscula
catch.error = function(x)
{
# let us create a missing value for test purpose
y = NA
# Try to catch that error (NA) we just created
catch_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(catch_error, "error"))
y = tolower(x)
# check result if error exists, otherwise the function works fine.
return(y)
}
#Función para limpiar el tweet
cleanTweets = function(tweet){
#  remove html links, which are not required for sentiment analysis
tweet = gsub("(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", " ", tweet)
# First we will remove retweet entities from the stored tweets (text)
tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", tweet)
# Then remove all "#Hashtag"
tweet = gsub("#\\w+", " ", tweet)
# Then remove all "@people"
tweet = gsub("@\\w+", " ", tweet)
# Then remove all the punctuation
#tweet = gsub("[[:punct:]]", " ", tweet)
# Then remove numbers, we need only text for analytics
tweet = gsub("[[:digit:]]", " ", tweet)
tweet = gsub("Ã¡", "a", tweet)
tweet = gsub("Ã©", "e", tweet)
tweet = gsub("Ã³", "o", tweet)
tweet = gsub("[[:punct:]]", " ", tweet)
tweet = gsub("ã", "i", tweet)
tweet = gsub("Ã ", "i", tweet)
# finally, we remove unnecessary spaces (white spaces, tabs etc)
tweet = gsub("[ \t]{2,}", " ", tweet)
tweet = gsub("^\\s+|\\s+$", "", tweet)
tweet = chartr('áéíóú','aeiou', tweet)
# if anything else, you feel, should be removed, you can. For example "slang words" etc using the above function and methods.
# Next we'll convert all the word in lower case. This makes uniform pattern.
tweet = catch.error(tweet)
tweet
}
cleanTweetsAndRemoveNAs = function(Tweets) {
TweetsCleaned = sapply(Tweets, cleanTweets)
# Remove the "NA" tweets from this tweet list
TweetsCleaned = TweetsCleaned[!is.na(TweetsCleaned)]
names(TweetsCleaned) = NULL
# Remove the repetitive tweets from this tweet list
TweetsCleaned = unique(TweetsCleaned)
TweetsCleaned
}
TextTweetsSpanish <- sapply(AnalisisTweetsSpanish, function(x) x$getText())
TextTweetsSpanish
TextTweetsSpanish = iconv(TextTweetsSpanish, "latin1", "UTF-8", sub="")
AnalisisTweetsLimpioSpanish = cleanTweetsAndRemoveNAs(TextTweetsSpanish)
AnalisisTweetsLimpioSpanish
TextTweetsSpanish <- sapply(AnalisisTweetsSpanish, function(x) x$getText())
TextTweetsSpanish
TextTweetsSpanish = iconv(TextTweetsSpanish, "latin1", "UTF-8", sub="")
TextTweetsSpanish
TextTweetsSpanish <- sapply(AnalisisTweetsSpanish, function(x) x$getText())
TextTweetsSpanish
TextTweetsSpanish = iconv(TextTweetsSpanish, "latin1", "UTF-8", sub="")
AnalisisTweetsLimpioSpanish = cleanTweetsAndRemoveNAs(TextTweetsSpanish)
AnalisisTweetsLimpioSpanish
tweet = "Hola España"
tweet = gsub("(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", " ", tweet)
# First we will remove retweet entities from the stored tweets (text)
tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", tweet)
# Then remove all "#Hashtag"
tweet = gsub("#\\w+", " ", tweet)
# Then remove all "@people"
tweet = gsub("@\\w+", " ", tweet)
# Then remove all the punctuation
#tweet = gsub("[[:punct:]]", " ", tweet)
# Then remove numbers, we need only text for analytics
tweet = gsub("[[:digit:]]", " ", tweet)
tweet = gsub("Ã¡", "a", tweet)
tweet = gsub("Ã©", "e", tweet)
tweet = gsub("[[:punct:]]", " ", tweet)
tweet = gsub("Ã³", "o", tweet)
tweet = gsub("ã", "i", tweet)
tweet
tendencia
tendencia = "#TetasSinCanones"
AnalisisTweetsSpanish = searchTwitter(tendencia, n, lang = lang, resultType = "recent")
AnalisisTweetsSpanish
#AnalisisTweetsSpanish = strip_retweets(AnalisisTweetsSpanish, strip_manual = TRUE, strip_mt = TRUE)
TextTweetsSpanish <- sapply(AnalisisTweetsSpanish, function(x) x$getText())
TextTweetsSpanish
TextTweetsSpanish = iconv(TextTweetsSpanish, "latin1", "UTF-8", sub="")
TextTweetsSpanish
AnalisisTweetsLimpioSpanish = cleanTweetsAndRemoveNAs(TextTweetsSpanish)
AnalisisTweetsLimpioSpanish
TextTweetsSpanish <- sapply(AnalisisTweetsSpanish, function(x) x$getText())
TextTweetsSpanish
TextTweetsSpanish = iconv(TextTweetsSpanish, "latin1", "UTF-8", sub="")
TextTweetsSpanish
library(stringr)
#Función para convertir en minuscula
catch.error = function(x)
{
# let us create a missing value for test purpose
y = NA
# Try to catch that error (NA) we just created
catch_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(catch_error, "error"))
y = tolower(x)
# check result if error exists, otherwise the function works fine.
return(y)
}
#Función para limpiar el tweet
cleanTweets = function(tweet){
#  remove html links, which are not required for sentiment analysis
tweet = gsub("(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", " ", tweet)
# First we will remove retweet entities from the stored tweets (text)
tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", tweet)
# Then remove all "#Hashtag"
tweet = gsub("#\\w+", " ", tweet)
# Then remove all "@people"
tweet = gsub("@\\w+", " ", tweet)
# Then remove all the punctuation
#tweet = gsub("[[:punct:]]", " ", tweet)
# Then remove numbers, we need only text for analytics
tweet = gsub("[[:digit:]]", " ", tweet)
tweet = gsub("Ã¡", "a", tweet)
tweet = gsub("Ã©", "e", tweet)
tweet = gsub("Ã³", "o", tweet)
tweet = gsub("[[:punct:]]", " ", tweet)
tweet = gsub("ã", "i", tweet)
tweet = gsub("Ã ", "i", tweet)
tweet = gsub("Ã±", "ñ", tweet)
# finally, we remove unnecessary spaces (white spaces, tabs etc)
tweet = gsub("[ \t]{2,}", " ", tweet)
tweet = gsub("^\\s+|\\s+$", "", tweet)
tweet = chartr('áéíóú','aeiou', tweet)
# if anything else, you feel, should be removed, you can. For example "slang words" etc using the above function and methods.
# Next we'll convert all the word in lower case. This makes uniform pattern.
tweet = catch.error(tweet)
tweet
}
cleanTweetsAndRemoveNAs = function(Tweets) {
TweetsCleaned = sapply(Tweets, cleanTweets)
# Remove the "NA" tweets from this tweet list
TweetsCleaned = TweetsCleaned[!is.na(TweetsCleaned)]
names(TweetsCleaned) = NULL
# Remove the repetitive tweets from this tweet list
TweetsCleaned = unique(TweetsCleaned)
TweetsCleaned
}
TextTweetsSpanish <- sapply(AnalisisTweetsSpanish, function(x) x$getText())
TextTweetsSpanish
TextTweetsSpanish = iconv(TextTweetsSpanish, "latin1", "UTF-8", sub="")
AnalisisTweetsLimpioSpanish = cleanTweetsAndRemoveNAs(TextTweetsSpanish)
AnalisisTweetsLimpioSpanish
TextTweetsSpanish <- sapply(AnalisisTweetsSpanish, function(x) x$getText())
TextTweetsSpanish
TextTweetsSpanish = iconv(TextTweetsSpanish, "latin1", "UTF-8", sub="")
TextTweetsSpanish
tweet = TextTweetSpanish[97]
tweet = TextTweetsSpanish[97]
tweet
tweet = gsub("[[:punct:]]", " ", tweet)
tweet
tweet = TextTweetsSpanish[97]
tweet
tweet = gsub("Ã¡", "a", tweet)
tweet = gsub("Ã©", "e", tweet)
tweet = gsub("Ã³", "o", tweet)
tweet = gsub("Ã±", "ñ", tweet)
tweet
tweet = gsub("[[:punct:]]", " ", tweet)
tweet
library(stringr)
#Función para convertir en minuscula
catch.error = function(x)
{
# let us create a missing value for test purpose
y = NA
# Try to catch that error (NA) we just created
catch_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(catch_error, "error"))
y = tolower(x)
# check result if error exists, otherwise the function works fine.
return(y)
}
#Función para limpiar el tweet
cleanTweets = function(tweet){
#  remove html links, which are not required for sentiment analysis
tweet = gsub("(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", " ", tweet)
# First we will remove retweet entities from the stored tweets (text)
tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", tweet)
# Then remove all "#Hashtag"
tweet = gsub("#\\w+", " ", tweet)
# Then remove all "@people"
tweet = gsub("@\\w+", " ", tweet)
# Then remove all the punctuation
#tweet = gsub("[[:punct:]]", " ", tweet)
# Then remove numbers, we need only text for analytics
tweet = gsub("[[:digit:]]", " ", tweet)
tweet = gsub("Ã¡", "a", tweet)
tweet = gsub("Ã©", "e", tweet)
tweet = gsub("Ã³", "o", tweet)
tweet = gsub("Ã±", "ñ", tweet)
tweet = gsub("[[:punct:]]", " ", tweet)
tweet = gsub("ã", "i", tweet)
tweet = gsub("Ã ", "i", tweet)
# finally, we remove unnecessary spaces (white spaces, tabs etc)
tweet = gsub("[ \t]{2,}", " ", tweet)
tweet = gsub("^\\s+|\\s+$", "", tweet)
tweet = chartr('áéíóú','aeiou', tweet)
# if anything else, you feel, should be removed, you can. For example "slang words" etc using the above function and methods.
# Next we'll convert all the word in lower case. This makes uniform pattern.
tweet = catch.error(tweet)
tweet
}
cleanTweetsAndRemoveNAs = function(Tweets) {
TweetsCleaned = sapply(Tweets, cleanTweets)
# Remove the "NA" tweets from this tweet list
TweetsCleaned = TweetsCleaned[!is.na(TweetsCleaned)]
names(TweetsCleaned) = NULL
# Remove the repetitive tweets from this tweet list
TweetsCleaned = unique(TweetsCleaned)
TweetsCleaned
}
TextTweetsSpanish <- sapply(AnalisisTweetsSpanish, function(x) x$getText())
TextTweetsSpanish
TextTweetsSpanish = iconv(TextTweetsSpanish, "latin1", "UTF-8", sub="")
AnalisisTweetsLimpioSpanish = cleanTweetsAndRemoveNAs(TextTweetsSpanish)
AnalisisTweetsLimpioSpanish
library(stringr)
#Función para convertir en minuscula
catch.error = function(x)
{
# let us create a missing value for test purpose
y = NA
# Try to catch that error (NA) we just created
catch_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(catch_error, "error"))
y = tolower(x)
# check result if error exists, otherwise the function works fine.
return(y)
}
#Función para limpiar el tweet
cleanTweets = function(tweet){
#  remove html links, which are not required for sentiment analysis
tweet = gsub("(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", " ", tweet)
# First we will remove retweet entities from the stored tweets (text)
tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", tweet)
# Then remove all "#Hashtag"
tweet = gsub("#\\w+", " ", tweet)
# Then remove all "@people"
tweet = gsub("@\\w+", " ", tweet)
# Then remove all the punctuation
#tweet = gsub("[[:punct:]]", " ", tweet)
# Then remove numbers, we need only text for analytics
tweet = gsub("[[:digit:]]", " ", tweet)
tweet = gsub("â", "¿", tweet)
tweet = gsub("Ã¡", "a", tweet)
tweet = gsub("Ã©", "e", tweet)
tweet = gsub("Ã³", "o", tweet)
tweet = gsub("Ã±", "ñ", tweet)
tweet = gsub("[[:punct:]]", " ", tweet)
tweet = gsub("ã", "i", tweet)
tweet = gsub("Ã ", "i", tweet)
# finally, we remove unnecessary spaces (white spaces, tabs etc)
tweet = gsub("[ \t]{2,}", " ", tweet)
tweet = gsub("^\\s+|\\s+$", "", tweet)
tweet = chartr('áéíóú','aeiou', tweet)
# if anything else, you feel, should be removed, you can. For example "slang words" etc using the above function and methods.
# Next we'll convert all the word in lower case. This makes uniform pattern.
tweet = catch.error(tweet)
tweet
}
cleanTweetsAndRemoveNAs = function(Tweets) {
TweetsCleaned = sapply(Tweets, cleanTweets)
# Remove the "NA" tweets from this tweet list
TweetsCleaned = TweetsCleaned[!is.na(TweetsCleaned)]
names(TweetsCleaned) = NULL
# Remove the repetitive tweets from this tweet list
TweetsCleaned = unique(TweetsCleaned)
TweetsCleaned
}
TextTweetsSpanish <- sapply(AnalisisTweetsSpanish, function(x) x$getText())
TextTweetsSpanish
TextTweetsSpanish = iconv(TextTweetsSpanish, "latin1", "UTF-8", sub="")
AnalisisTweetsLimpioSpanish = cleanTweetsAndRemoveNAs(TextTweetsSpanish)
AnalisisTweetsLimpioSpanish
library(stringr)
#Función para convertir en minuscula
catch.error = function(x)
{
# let us create a missing value for test purpose
y = NA
# Try to catch that error (NA) we just created
catch_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(catch_error, "error"))
y = tolower(x)
# check result if error exists, otherwise the function works fine.
return(y)
}
#Función para limpiar el tweet
cleanTweets = function(tweet){
#  remove html links, which are not required for sentiment analysis
tweet = gsub("(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", " ", tweet)
# First we will remove retweet entities from the stored tweets (text)
tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", tweet)
# Then remove all "#Hashtag"
tweet = gsub("#\\w+", " ", tweet)
# Then remove all "@people"
tweet = gsub("@\\w+", " ", tweet)
# Then remove all the punctuation
#tweet = gsub("[[:punct:]]", " ", tweet)
# Then remove numbers, we need only text for analytics
tweet = gsub("[[:digit:]]", " ", tweet)
tweet = gsub("â", "¿", tweet)
tweet = gsub("Ã¡", "a", tweet)
tweet = gsub("Ã©", "e", tweet)
tweet = gsub("Ã³", "o", tweet)
tweet = gsub("Ã±", "ñ", tweet)
tweet = gsub("[[:punct:]]", " ", tweet)
tweet = gsub("ã", "i", tweet)
tweet = gsub("Ã ", "i", tweet)
tweet = gsub("\n", " ", tweet)
# finally, we remove unnecessary spaces (white spaces, tabs etc)
tweet = gsub("[ \t]{2,}", " ", tweet)
tweet = gsub("^\\s+|\\s+$", "", tweet)
tweet = chartr('áéíóú','aeiou', tweet)
# if anything else, you feel, should be removed, you can. For example "slang words" etc using the above function and methods.
# Next we'll convert all the word in lower case. This makes uniform pattern.
tweet = catch.error(tweet)
tweet
}
cleanTweetsAndRemoveNAs = function(Tweets) {
TweetsCleaned = sapply(Tweets, cleanTweets)
# Remove the "NA" tweets from this tweet list
TweetsCleaned = TweetsCleaned[!is.na(TweetsCleaned)]
names(TweetsCleaned) = NULL
# Remove the repetitive tweets from this tweet list
TweetsCleaned = unique(TweetsCleaned)
TweetsCleaned
}
TextTweetsSpanish <- sapply(AnalisisTweetsSpanish, function(x) x$getText())
TextTweetsSpanish
TextTweetsSpanish = iconv(TextTweetsSpanish, "latin1", "UTF-8", sub="")
AnalisisTweetsLimpioSpanish = cleanTweetsAndRemoveNAs(TextTweetsSpanish)
AnalisisTweetsLimpioSpanish
TextTweetsSpanish <- sapply(AnalisisTweetsSpanish, function(x) x$getText())
TextTweetsSpanish
TextTweetsSpanish = iconv(TextTweetsSpanish, "latin1", "UTF-8", sub="")
TextTweetsSpanish
TextTweetsSpanish = iconv(TextTweetsSpanish, "latin1", "UTF-8", sub="")
TextTweetsSpanish
TextTweetsSpanish = iconv(TextTweetsSpanish, "latin1", "UTF-8", sub="")
AnalisisTweetsLimpioSpanish = cleanTweetsAndRemoveNAs(TextTweetsSpanish)
AnalisisTweetsLimpioSpanish
TextTweetsSpanish <- sapply(AnalisisTweetsSpanish, function(x) x$getText())
TextTweetsSpanish
TextTweetsSpanish = iconv(TextTweetsSpanish, "latin1", "UTF-8", sub="")
TextTweetsSpanish
runApp()
runApp()
tendencia = "Monfils"
AnalisisTweetsSpanish = searchTwitter(tendencia, n, lang = lang, resultType = "recent")
AnalisisTweetsSpanish
#AnalisisTweetsSpanish = strip_retweets(AnalisisTweetsSpanish, strip_manual = TRUE, strip_mt = TRUE)
TextTweetsSpanish <- sapply(AnalisisTweetsSpanish, function(x) x$getText())
TextTweetsSpanish
TextTweetsSpanish = iconv(TextTweetsSpanish, "latin1", "UTF-8", sub="")
TextTweetsSpanish
AnalisisTweetsLimpioSpanish = cleanTweetsAndRemoveNAs(TextTweetsSpanish)
AnalisisTweetsLimpioSpanish
TextTweetsSpanish <- sapply(AnalisisTweetsSpanish, function(x) x$getText())
TextTweetsSpanish
TextTweetsSpanish = iconv(TextTweetsSpanish, "latin1", "UTF-8", sub="")
TextTweetsSpanish
tweet = TextTweetsSpanish[1]
tweet
tweet = TextTweetsSpanish[100]
tweet
tweet = TextTweetsSpanish[99]
tweet
tweet = gsub("(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", " ", tweet)
tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", tweet)
# Then remove all "#Hashtag"
tweet = gsub("#\\w+", " ", tweet)
# Then remove all "@people"
tweet = gsub("@\\w+", " ", tweet)
# Then remove all the punctuation
#tweet = gsub("[[:punct:]]", " ", tweet)
# Then remove numbers, we need only text for analytics
tweet = gsub("[[:digit:]]", " ", tweet)
tweet
tweet = TextTweetsSpanish[99]
tweet = gsub("(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", " ", tweet)
tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", tweet)
# First we will remove retweet entities from the stored tweets (text)
# Then remove all "#Hashtag"
tweet = gsub("#\\w+", " ", tweet)
# Then remove all "@people"
tweet = gsub("@\\w+", " ", tweet)
tweet
tweet = gsub("â", "¿", tweet)
tweet = gsub("Ã¡", "a", tweet)
tweet = gsub("Ã©", "e", tweet)
tweet = gsub("Ã³", "o", tweet)
tweet = gsub("Ã±", "ñ", tweet)
tweet = gsub("[[:punct:]]", " ", tweet)
tweet
tweet = gsub("ã", "i", tweet)
tweet = gsub("Ã ", "i", tweet)
tweet = gsub("[[:digit:]]", " ", tweet)
tweet = gsub("\n", " ", tweet)
tweet
library(stringr)
#Función para convertir en minuscula
catch.error = function(x)
{
# let us create a missing value for test purpose
y = NA
# Try to catch that error (NA) we just created
catch_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(catch_error, "error"))
y = tolower(x)
# check result if error exists, otherwise the function works fine.
return(y)
}
#Función para limpiar el tweet
cleanTweets = function(tweet){
#  remove html links, which are not required for sentiment analysis
tweet = gsub("(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", " ", tweet)
# First we will remove retweet entities from the stored tweets (text)
tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", tweet)
# Then remove all "#Hashtag"
tweet = gsub("#\\w+", " ", tweet)
# Then remove all "@people"
tweet = gsub("@\\w+", " ", tweet)
# Then remove all the punctuation
#tweet = gsub("[[:punct:]]", " ", tweet)
# Then remove numbers, we need only text for analytics
tweet = gsub("â", "¿", tweet)
tweet = gsub("Ã¡", "a", tweet)
tweet = gsub("Ã©", "e", tweet)
tweet = gsub("Ã³", "o", tweet)
tweet = gsub("Ã±", "ñ", tweet)
tweet = gsub("[[:punct:]]", " ", tweet)
tweet = gsub("ã", "i", tweet)
tweet = gsub("Ã ", "i", tweet)
tweet = gsub("[[:digit:]]", " ", tweet)
tweet = gsub("\n", " ", tweet)
# finally, we remove unnecessary spaces (white spaces, tabs etc)
tweet = gsub("[ \t]{2,}", " ", tweet)
tweet = gsub("^\\s+|\\s+$", "", tweet)
tweet = chartr('áéíóú','aeiou', tweet)
# if anything else, you feel, should be removed, you can. For example "slang words" etc using the above function and methods.
# Next we'll convert all the word in lower case. This makes uniform pattern.
tweet = catch.error(tweet)
tweet
}
cleanTweetsAndRemoveNAs = function(Tweets) {
TweetsCleaned = sapply(Tweets, cleanTweets)
# Remove the "NA" tweets from this tweet list
TweetsCleaned = TweetsCleaned[!is.na(TweetsCleaned)]
names(TweetsCleaned) = NULL
# Remove the repetitive tweets from this tweet list
TweetsCleaned = unique(TweetsCleaned)
TweetsCleaned
}
TextTweetsSpanish <- sapply(AnalisisTweetsSpanish, function(x) x$getText())
TextTweetsSpanish = iconv(TextTweetsSpanish, "latin1", "UTF-8", sub="")
TextTweetsSpanish
AnalisisTweetsLimpioSpanish = cleanTweetsAndRemoveNAs(TextTweetsSpanish)
AnalisisTweetsLimpioSpanish
runApp()
